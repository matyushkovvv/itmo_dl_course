{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6224ba9924174f70a312745d1f607abc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3d1bb9458c5a4f08aa5369e29ad78bf3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/9  \u001b[38;2;98;6;224m━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 67/391 \u001b[2m0:00:22 • 0:01:45\u001b[0m \u001b[2;4m3.10it/s\u001b[0m \u001b[3mv_num: 0.000 train_loss: 0.653\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/9  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 67/391 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:22 • 0:01:45</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">3.10it/s</span> <span style=\"font-style: italic\">v_num: 0.000 train_loss: 0.653</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "3d1bb9458c5a4f08aa5369e29ad78bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Реализация дата класса"
      ],
      "metadata": {
        "id": "QdEYs_8qjwnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightning torchmetrics"
      ],
      "metadata": {
        "id": "YAxKECeiubFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea537c7-f849-42d6-feab-e4dce7882f39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lC3P7TK1jVUw"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTDataModule(L.LightningDataModule):\n",
        "    def __init__(self, data_dir: str = \"./data\", batch_size: int = 128, num_workers: int = 2):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        # Трансформации\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.2860,), (0.3530,))\n",
        "        ])\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def prepare_data(self):\n",
        "        FashionMNIST(self.data_dir, train=True, download=True)\n",
        "        FashionMNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "        # Полный тренировочный набор\n",
        "        full_train = FashionMNIST(\n",
        "            self.data_dir,\n",
        "            train=True,\n",
        "            transform=self.transform\n",
        "        )\n",
        "\n",
        "        # Тестовый набор\n",
        "        self.test_dataset = FashionMNIST(\n",
        "            self.data_dir,\n",
        "            train=False,\n",
        "            transform=self.transform\n",
        "        )\n",
        "\n",
        "        # Разделяем на train/val\n",
        "        self.train_dataset, self.val_dataset = random_split(\n",
        "            full_train,\n",
        "            [50000, 10000]\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=min(self.num_workers, 2),\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=min(self.num_workers, 2),\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=min(self.num_workers, 2),\n",
        "            pin_memory=True\n",
        "        )"
      ],
      "metadata": {
        "id": "_b6wGVHdj37Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация классификатора"
      ],
      "metadata": {
        "id": "IP3evc_Nvlyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy, F1Score, ROC, AUROC\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "PtufotVOwgtK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTClassifier(L.LightningModule):\n",
        "    def __init__(self, learning_rate: float = 1e-3, weight_decay: float = 1e-4):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, padding=1),\n",
        "            nn.Dropout2d(0.3),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.training_step_outputs = []\n",
        "        self.validation_step_outputs = []\n",
        "        self.test_step_outputs = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.conv_layers(x)\n",
        "        return self.classifier(features)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.train_acc.update(preds, y)\n",
        "\n",
        "        self.training_step_outputs.append({'loss': loss, 'preds': preds, 'targets': y})\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        epoch_acc = self.train_acc.compute()\n",
        "        self.log('train_acc_epoch', epoch_acc, prog_bar=True)\n",
        "        print(f\"[Epoch {self.current_epoch}] Train Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "        self.training_step_outputs.clear()\n",
        "        self.train_acc.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.val_acc.update(preds, y)\n",
        "\n",
        "        self.validation_step_outputs.append({'loss': loss, 'preds': preds, 'targets': y})\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        epoch_acc = self.val_acc.compute()\n",
        "        self.log('val_acc_epoch', epoch_acc, prog_bar=True)\n",
        "        print(f\"[Epoch {self.current_epoch}] Val Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "        self.validation_step_outputs.clear()\n",
        "        self.val_acc.reset()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.test_acc.update(preds, y)\n",
        "\n",
        "        self.test_step_outputs.append({'loss': loss, 'preds': preds, 'targets': y})\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        test_accuracy = self.test_acc.compute()\n",
        "        self.log('test_acc_epoch', test_accuracy, prog_bar=True)\n",
        "\n",
        "        self.test_step_outputs.clear()\n",
        "        self.test_acc.reset()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.learning_rate,\n",
        "            weight_decay=self.weight_decay\n",
        "        )\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=self.trainer.max_epochs if self.trainer else 10\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'interval': 'epoch',\n",
        "                'frequency': 1\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "Mrma23S5sFFw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_visualization():\n",
        "    print(\"Инициализация...\")\n",
        "    dm = FashionMNISTDataModule(batch_size=128)\n",
        "    model = FashionMNISTClassifier(learning_rate=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    logger = TensorBoardLogger(\"tb_logs\", name=f\"fashion_mnist_{timestamp}\")\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        mode='min',\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor='val_acc_epoch',\n",
        "        mode='max',\n",
        "        filename='best-{epoch:02d}-{val_acc_epoch:.3f}',\n",
        "        save_top_k=1,\n",
        "        save_last=True\n",
        "    )\n",
        "\n",
        "    trainer = L.Trainer(\n",
        "        max_epochs=10,\n",
        "        accelerator=\"auto\",\n",
        "        devices=1,\n",
        "        logger=logger,\n",
        "        callbacks=[early_stopping, checkpoint_callback],\n",
        "        enable_progress_bar=True,\n",
        "        log_every_n_steps=10,\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTensorBoard логи: {logger.log_dir}\")\n",
        "    print(\"Checkpoint будет сохранен по лучшему val_acc_epoch\")\n",
        "    print(\"\\nНачало обучения...\")\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    print(f\"\\nОбучение завершено. Лучшая модель: {checkpoint_callback.best_model_path}\")\n",
        "\n",
        "    print(\"\\nТестирование лучшей модели...\")\n",
        "    if checkpoint_callback.best_model_path:\n",
        "        best_model = FashionMNISTClassifier.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
        "        trainer.test(best_model, dm)\n",
        "    else:\n",
        "        trainer.test(model, dm)\n",
        "\n",
        "    return model, trainer, logger"
      ],
      "metadata": {
        "id": "c4E6EBgR4qjj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model, trainer, logger = train_with_visualization()\n",
        "\n",
        "    print(\"\\nЗапуск TensorBoard...\")\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir tb_logs/\n",
        "\n",
        "    print(\"\\nОбучение и тестирование завершены!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "6224ba9924174f70a312745d1f607abc",
            "3d1bb9458c5a4f08aa5369e29ad78bf3"
          ]
        },
        "id": "F3OiQgiSfm93",
        "outputId": "fdda5fb4-4467-44a2-f926-0b40c5954c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Инициализация...\n",
            "\n",
            "TensorBoard логи: tb_logs/fashion_mnist_20251228_133634/version_0\n",
            "Checkpoint будет сохранен по лучшему val_acc_epoch\n",
            "\n",
            "Начало обучения...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ conv_layers │ Sequential         │ 93.1 K │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ classifier  │ Sequential         │  1.1 M │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ train_acc   │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ val_acc     │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ test_acc    │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ criterion   │ CrossEntropyLoss   │      0 │ train │     0 │\n",
              "└───┴─────────────┴────────────────────┴────────┴───────┴───────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ conv_layers │ Sequential         │ 93.1 K │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ classifier  │ Sequential         │  1.1 M │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ train_acc   │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_acc     │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ test_acc    │ MulticlassAccuracy │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ criterion   │ CrossEntropyLoss   │      0 │ train │     0 │\n",
              "└───┴─────────────┴────────────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 1.1 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 1.1 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.1 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 1.1 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 4                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6224ba9924174f70a312745d1f607abc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is \n",
              "set as true but no accelerator is found, then device pinned memory won't be used.\n",
              "  warnings.warn(warn_msg)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is \n",
              "set as true but no accelerator is found, then device pinned memory won't be used.\n",
              "  warnings.warn(warn_msg)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Epoch 0] Val Accuracy: 0.1172\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Epoch 0] Val Accuracy: 0.1172\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}